<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Parametric Manifold Learning of Gaussian Mixture Models | Shirley</title><meta name="description" content="Parametric Manifold Learning of Gaussian Mixture Models"><meta name="keywords" content="Gaussian,PaperList"><meta name="author" content="Shirley Zhu"><meta name="copyright" content="Shirley Zhu"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="http://zhuhanchn.github.io/2019/08/18/ijcai2019_PMLGMM/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Parametric Manifold Learning of Gaussian Mixture Models"><meta name="twitter:description" content="Parametric Manifold Learning of Gaussian Mixture Models"><meta name="twitter:image" content="https://i.loli.net/2019/08/18/Vgsrlz7FSHRZ2Dk.png"><meta property="og:type" content="article"><meta property="og:title" content="Parametric Manifold Learning of Gaussian Mixture Models"><meta property="og:url" content="http://zhuhanchn.github.io/2019/08/18/ijcai2019_PMLGMM/"><meta property="og:site_name" content="Shirley"><meta property="og:description" content="Parametric Manifold Learning of Gaussian Mixture Models"><meta property="og:image" content="https://i.loli.net/2019/08/18/Vgsrlz7FSHRZ2Dk.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="next" title="Hexo博客基本操作" href="http://zhuhanchn.github.io/2019/08/18/basic_operation/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天'

  
}</script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#摘要"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-简介"><span class="toc-number">2.</span> <span class="toc-text">1 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-相关工作"><span class="toc-number">3.</span> <span class="toc-text">2 相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3"><span class="toc-number">4.</span> <span class="toc-text">3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-实验"><span class="toc-number">5.</span> <span class="toc-text">4 实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1定量结果摘要"><span class="toc-number">5.1.</span> <span class="toc-text">4.1定量结果摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2合成数据"><span class="toc-number">5.2.</span> <span class="toc-text">4.2合成数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3眼睛固定数据"><span class="toc-number">5.3.</span> <span class="toc-text">4.3眼睛固定数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4流式细胞仪数据"><span class="toc-number">5.4.</span> <span class="toc-text">4.4流式细胞仪数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-结论"><span class="toc-number">6.</span> <span class="toc-text">5 结论</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://i.loli.net/2019/08/18/Vgsrlz7FSHRZ2Dk.png)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/">Shirley</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><span class="pull-right menus"><div class="mobile_author_icon"><img class="lozad" src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'"><div class="mobile_author-info__description"></div></div><hr><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Parametric Manifold Learning of Gaussian Mixture Models</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-08-18<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-08-18</time></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><ul>
<li>高斯混合模型的参数流形学习</li>
</ul>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>高斯混合模型（GMM）是用于表示数据的最广泛使用的参数概率分布之一。然而，分析GMM之间的关系是很复杂的，因为它们位于高维流形上。以前的工作要么执行GMM的聚类，它学习有限的离散潜在表示，要么基于内核的GMM嵌入，它难以计算逆映射而无法解释。在本文中，我们提出GMM的参数流形学习（PMLGMM），它学习从低维潜在空间到高维GMM流形的参数映射。与PCA类似，所提出的映射由组件权重，平均值和协方差的主轴参数化，其被优化以最小化使用Kullback-Leibler散度（KLD）测量的重建损失。由于两个GMM之间的KLD是难以处理的，我们通过变分上界来近似目标函数，该上界由EM样式算法优化。<br>此外，我们通过交替优化子问题并利用蒙特卡罗采样来逃避局部最小值，从而得到一个有效的求解器。我们通过合成，眼睛固定，流式细胞仪和社会登记数据的实验证明了PML-GMM的有效性。</p>
<hr>
<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h2><p>概率模型是在存在噪声的情况下表示现实世界数据的有效工具。例如，高斯混合模型（GMM）被认为是计算机视觉中的通用视觉词汇[S’anchez et al。，2013; Winn等，2005; Perronnin等，2006]由于其能够对图像斑块中的平均值和相关性进行建模;隐马尔可夫模型（HMM）通常用于在自然语言处理中对语音序列进行建模[Rabiner，1989]，因为它可以模拟隐藏（基础）过程和观察到的语音序列的动态;线性动力系统（动态纹理，DT）用于描述视频，因为它可以抽象复杂的运动和外观模式[Doretto et al。，2003]。聚类概率模型可以产生数据的分层表示，其可以用于检索，注释，索引和码本生成。以前的工作已经开发出用于高斯分布的聚类算法[Yu et al。，2018; Vasconcelos和Lippman，1999]，DTs [Chan et al。，2010]和HMMs [Coviello et al。，2012]。</p>
<hr>
<p>虽然聚类概率模型可以给出层次表示，但它无法学习连续和可解释的流形，在这些流形上我们可以看到概率模型之间的连续变化。在各种应用领域，例如医学诊断[Carter et al。，2009]，行为分析[Chan et al。，2018]和视觉识别[Perronnin et al。，2006]，这种可解释的流形提供了对该主题的更好的洞察差异和潜在的机制。例如，假设我们从几个科目收集数据，并为每个科目的数据学习科目级GMM。可以聚集GMM以获得对象之间的共同模式，但是这提供了有限的离散表示（K个群集之一）。或者，如果GMM嵌入歧管中，则歧管上的受试者坐标是连续的，并且可以使用相关性分析揭示它们与其他受试者属性（例如，受试者年龄，表现）的关系。此外，歧管上的方向将对应于GMM结构的变化，从而提供对揭示的相关性的潜在机制的洞察。尽管其重要性，但对概率模型的多种学习尚未得到很好的探索。</p>
<hr>
<p>在本文中，我们建议学习GMM的平滑和可解释的流形，其中可以容易地获得低维潜在空间和高维统计流形之间的逆映射。受PCA的启发，我们提出了一种用于学习分布流形的参数方法。组件先验，均值和协方差f k; k; kgKb k = 1的GMM参数均由它们自己的主轴表示。潜在空间（w; z; y）是主轴上的系数，并将它们投影到主轴上产生GMM参数。图1a说明了统计流形和潜在空间之间的映射。通过最小化原始GMM与其通过潜在空间的重建之间的KL偏差，我们获得了f􀀀1中的参数，并且还获得了统计流形的连续且可解释的潜在空间。此外，潜在空间（w; z; y）被映射到分层潜在空间v以进一步减小尺寸（见图1b），其模拟潜在空间系数之间的依赖性（因此在组件先验之间，意味着，和协方差）。</p>
<hr>
<p>我们的贡献是三方面的：1）我们提出了一个GMM参数流形，可以从潜在变量中明确生成; 2）我们提出了一种基于变分近似的优化方法来学习参数映射，并通过交替优化和Metroplis-Hastings采样得到快速求解器; 3）我们凭经验证明我们的方法可以很好地重建GMMs，并在几个应用领域中学习一个平滑且可解释的潜在空间。</p>
<hr>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><p>给定一组概率模型（PM），每个PM代表<br>在数据集中的一个示例中，可以通过聚类来揭示PM之间的关系，以获得离散的共同模型组，或者通过降维，以获得潜在空间，其中潜在空间中的方向对应于PM中的变化。<br>分层EM（HEM）算法是聚类PM的开创性工作[Vasconcelos和Lippman，1999]，并且首次提出聚类高斯分布。将高斯收集到“基础”GMM中，从中估计出“减少的”GMM，其中组件数量较少。缩小的GMM中的分量用作聚类的代表性高斯，并且聚类成员在基本GMM的高斯和减少的GMM之间映射。为了避免高计算成本，虚拟样本是<br>从基础GMM生成并且导出封闭形式的解决方案，其根据基础GMM的参数表示减小的GMM。后来，HEM扩展到集群时间序列PM：DTs [Chan et al。，2010]和HMMs [Coviello et al。，2012]。由于最初的HEM算法是为聚类而推导的，[Yu et al。，2018]最近提出了一种密度保持HEM算法，用于将GMM简化为具有较少分量的等效GMM，同时最小化由KLD测量的失真。</p>
<hr>
<p>这些聚类方法仅获得该组PM的离散表示，即一组有限的代表性模型和聚类分配。相反，我们建议学习多种PM，这是由潜在空间系数指定的代表性模型的连续体。因此，我们的模型可以更好地可视化PM结构的变化。</p>
<p>在我们的学习算法中，我们采用了对预期对数似然的变分近似，这类似于DPHEM [Yu et al。，2018]。主要区别在于DPHEM采用单个输入GMM并减少组件数量以获得单个输出GMM。相比之下，我们的公式采用一组GMM，并通过最小化GMM的重建损失将它们嵌入到参数流形中。当存在一个输入GMM和Km &lt;Kb时，DPHEM是我们框架的特例，其中Km和Kb分别是重构GMM和输入GMM中的分量数。此外，本文中的EM算法在M步骤中没有封闭形式的解决方案，而DPHEM的简单M步骤具有封闭形式的解决方案。</p>
<hr>
<p>PM的维数降低有两种通用方法：内核嵌入和潜变量模型。内核嵌入使用内核函数（或距离函数）显式地模拟从输入空间到潜在变量的映射。因此，通过在概率分布上使用适当定义的核函数，可以将PM嵌入到低维空间中。例如，内核PCA [Sch¨olkopf等，1998]可以与KL内核[Moreno et al。，2004]或概率产品内核[Jebara et al。，2004]一起使用来对一组进行降维。转基因微生物。基于信息几何[Amari和Nagaoka，2007]，[Carter et al。，2009]提出Fisher信息非参数嵌入（FINE），它计算黎曼流形分布上的测地线，然后使用多维缩放（MDS）获得嵌入。这些内核方法的优点是可以明确地获得从分布到嵌入坐标的前向映射。然而，缺点是难以从嵌入坐标到分布的逆映射并且需要解决前映像问题，这阻碍了嵌入空间的解释及其与输入空间的关系。与内核方法相比，我们的方法显式构造了从潜在空间到概率空间的逆映射。</p>
<hr>
<p>潜变量模型以相反的方式解决问题：它们模拟生成过程，即从低维潜在变量到高维变量的逆映射。 例如，高斯过程潜变量模型（GPLVM）[Lawrence，2004]使用潜在变量上的核矩阵获得非线性逆映射。 然而，高维变量仍然被视为向量，因此GPLVM不能自然地表示结构化的非向量数据，例如概率分布。 虽然也可以对高维变量进行核化，但这会导致与上面的KPCA相同的前映像问题。 与GPLVM类似，我们的方法也是一个生成模型，但与GPLVM相比，我们构造了一个显式参数<br>从潜在空间映射到概率分布。</p>
<hr>
<p>AutoEncoders（AE）是具有潜在变量的另一种非线性嵌入方法。 AE首先将输入矢量映射到潜在空间（编码器），然后从潜在变量（解码器）重建输入矢量。 使用神经网络编码器/解码器，AE可以为高调暗输入向量建模复杂的映射函数。 然而，之前的AE工作没有考虑如何处理多模态分布输入，例如GMM  - 使用矢量化GMM作为AE的输入不解决由组件排列引起的可识别性问题。 由于KLD损失和变分参数作为指配指标，我们的方法对于组件置换是不变的。</p>
<hr>
<h2 id="3"><a href="#3" class="headerlink" title="3"></a>3</h2><hr>
<h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h2><p>为了证明我们的方法的有效性，我们在四个不同的领域进行GMMs实验：1）合成数据，2）流式细胞术数据[Aghaeepour等，2013]，3）眼固定数据[Chan et al。，2018]和4）社会登记数据[Cho et al。，2011]。为了进行比较，我们还使用GPLVM和KPCA来学习潜在空间，两者都使用高斯内核进行矢量输入。为了将GMM转换为矢量，我们首先变换其参数，以便在重建阶段获得有效的GMM  - 我们使用逆softmax函数映射先前的无约束空间，并对协方差矩阵使用Cholesky分解。然后将GMM的变换参数连接成长矢量。由于GMM向量由连接期间组件的顺序确定，因此组件顺序将影响嵌入的结果。我们将订单标准化如下。对于数据集中的所有GMM，将每个高斯分量的参数转换为矢量。然后使用PCA映射到1-D线。然后，每个高斯分量的PCA系数确定串联期间的顺序。最后，我们与FINE [Carter et al。，2009]进行比较，后者最初将高斯嵌入到低维空间中，将其扩展为嵌入GMM。 GMM之间的KLD通过变分近似计算[Hershey and Olsen，2007]。</p>
<hr>
<p>我们以4种方式评估这些方法：1）在持续的GMM测试集上的KLD重建损失; 2）潜在空间与其他因变量（元数据）的相关性; 3）在潜在空间中使用潜在判别分析（LDA）进行分类精度; 4）GMM流形的可视化。 具体来说，对于（3），我们使用LDA从训练的潜在变量中学习一维判别空间，然后将测试潜在变量映射到同一空间并使用k最近邻居进行分类。 准确度衡量潜在空间和数据标签之间的相关性，以及下游任务中潜在变量的有效性。 眼睛固定，流式细胞仪和社交登记数据集的类别标签分别是年龄/年轻，健康/不健康和生活城市。 请注意，我们将社会登记数据的实验结果放在补充[Liu et al。，2019]中。</p>
<hr>
<h3 id="4-1定量结果摘要"><a href="#4-1定量结果摘要" class="headerlink" title="4.1定量结果摘要"></a>4.1定量结果摘要</h3><p>我们首先基于保持的测试数据的重建损失以及在潜在空间中使用LDA的测试精度来呈现方法的定量评估。 表1显示了结果。 在重建损失方面，PML-GMM优于其他方法，这表明它可以很好地推广到新型GMM。 对于精度度量，PMLGMM优于KPCA和FINE。 当组件号较小时，PML-GMM获得与GPLVM相同的性能，Kb = f1; 2g流式细胞仪。 但是，当Kb增加（综合和社交签入）时，由于向量化GMM参数时的组件排序问题，GPLVM表现更差。 这些结果表明，通过PML-GMM获得的潜在空间在揭示数据中的底层结构方面更有效。</p>
<hr>
<h3 id="4-2合成数据"><a href="#4-2合成数据" class="headerlink" title="4.2合成数据"></a>4.2合成数据</h3><p>合成数据集由39个合成GMM和10个成分组成，根据一些潜在函数（见补充[Liu et al。，2019]），其均值和协方差由1D潜在空间产生（图2（a1））， 而先辈们是统一的。 20个GMM用于训练（蓝点），其他19个（红点）用于测试。 为了公平比较，对于所有方法，潜在空间维度设置为1。 与其他方法相比，PML-GMM学习平滑的潜在空间并获得最佳重建误差（表1）。 KPCA既不重建GMM也不学习光滑的潜在空间。 GPLVM重建了一些GMM，但在其他GMM上失败，潜在的空间与基本事实不一致。 在[Liu et al。，2019]中查看更多可视化。</p>
<hr>
<p>我们的框架使用两阶段估计程序：1）使用GMM汇总数据子集（例如，对应于主题）; 2）GMM流形是从各个GMM估计的。 我们框架的一个合理替代方案是直接从数据样本中学习GMM流形，表示为Direct-PML（参见补充[Liu et al。，2019]）。 图2（5）显示了使用Direct-PML学习多种合成GMM的实例。 与PML-GMM相比，Direct-PML既不能学习良好的GMM流形（平均KLD损失2.749），也不能学习正确的潜在空间。</p>
<hr>
<h3 id="4-3眼睛固定数据"><a href="#4-3眼睛固定数据" class="headerlink" title="4.3眼睛固定数据"></a>4.3眼睛固定数据</h3><p>眼睛固定数据[Chan et al。，2018]由34名年轻人和67名老年人（34名用于训练，33名用于测试）的眼睛固定坐标组成。 我们用GMM模拟每个人的眼睛固定模式，其中每个高斯分量对应于面部上的感兴趣区域（ROI）。 如[Chan et al。，2018]所建议的，我们使用对应于3个ROI的K = 3个分量。 对于PML-GMM，潜在空间设置为6维（dw = dz = dy = 2），并且HLS设置为dv = 3。</p>
<hr>
<p>潜伏空间如图3所示。只有在PML-GMM潜伏空间（图3a），我们才观察到老年人（AD象限）和年轻人（CD象限）成年人有不同的区域，并且测试数据 由老年人（黑色加点）组成，都嵌入旧区域（AD象限）。 相比之下，其他三种方法以不合需要的方式将测试GMM嵌入其潜在空间（参见表1中的LDA精度）。 我们使用多元线性回归分析检查HLS与受试者年龄之间的相关性（见2）。 PML的HLS与统计学上显着水平的年龄相关并且具有最大的R2统计量。</p>
<hr>
<p>对于PML，我们沿着图4b中的两个主轴可视化歧管。 沿着AB，从质心朝向A显示垂直形状的ROI向上朝向脸部的上部中心，并且朝向B示出在鼻子处的垂直形状的ROI和在眼睛周围的更水平形状的ROI。 沿着CD，从质心到C显示水平形状的ROI向上，而朝向D显示垂直形状的ROI向下。 由于老年人的投资回报率集中在面部中线，因此他们的投资回报率是垂直形状，因此它们嵌入到AD象限中。 相比之下，年轻人环顾眼睛周围区域并在眼睛周围具有水平ROI，因此它们嵌入BC象限。 这一发现与之前的论文[Chan et al。，2018]一致，但我们可视化眼睛凝视策略的连续变化，而不是像[Chan et al。，2018]中那样只有离散的团簇。</p>
<hr>
<h3 id="4-4流式细胞仪数据"><a href="#4-4流式细胞仪数据" class="headerlink" title="4.4流式细胞仪数据"></a>4.4流式细胞仪数据</h3><p>流式细胞术数据用于医学诊断，通过测量患者的细胞特性来测试不健康的疾病。流式细胞术数据样本的维数范围为5-8，并且一个患者的点数通常为数千，这使得直接分析变得麻烦。在这里，我们使用具有7维特征的开放式AML数据集[Aghaeepour等，2013]。 30名健康患者和30名不健康患者用于培训，另外10名健康患者和10名不健康患者用于检测。我们使用与Sec相同的LS / HLS维度。 4.3。我们使用K 2 f2对每个患者的数据运行EM; 3; 4; 5g并发现当K&gt; 2时，有许多受试者（&gt; 80％）具有低重量成分。因此，我们使用Kb = 2或Kb = 1 GMM来模拟每个患者。尽管PML-GMM和GPLVM在分类精度方面表现相同，但PMLGMM的重建损失比GPLVM低43％（见表1）。此外，PML-GMM可以很容易地从潜在空间可视化GMM（见图5），而GPLVM由于重建损失较差而无法提供良好的可视化。在图5b中，EF显示通过逐渐分离两种组分，不健康细胞变为健康细胞。 GH显示不健康和健康之间的区域，包括1组分（不健康）和2组分GMMs（健康）。关于KPCA，GPLVM和FINE学习的潜在空间，参见[Liu et al。，2019]。</p>
<hr>
<h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><p>在本文中，我们提出了一种参数化方法来学习GMM的流形，它们都学习从潜在空间到GMM参数的参数映射，并获得连续且可解释的潜在空间。 未来的工作将通过非线性映射提高HLS的表示能力，并将PML扩展到其他重要的概率模型，如HMM。</p>
<hr>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Shirley Zhu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://zhuhanchn.github.io/2019/08/18/ijcai2019_PMLGMM/">http://zhuhanchn.github.io/2019/08/18/ijcai2019_PMLGMM/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://zhuhanchn.github.io">Shirley</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Gaussian/">Gaussian    </a><a class="post-meta__tags" href="/tags/PaperList/">PaperList    </a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2019/08/18/Vgsrlz7FSHRZ2Dk.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-buttom"><i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/alipay.jpg"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2019/08/18/basic_operation/"><img class="next_cover lozad" data-src="https://i.loli.net/2019/08/18/3q2WiZL9N7IdoC1.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>Hexo博客基本操作</span></div></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2019 By Shirley Zhu</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><i class="fa fa-book" id="readmode" title="阅读模式"> </i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="fa fa-moon-o nightshift" id="nightshift" title="夜间模式"></i></section><div id="post_bottom"><div id="post_bottom_items"><a id="to_comment" href="#post-comment"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list" id="mobile_toc"></i><div id="toc_mobile"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#摘要"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">摘要</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-简介"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">1 简介</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-相关工作"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">2 相关工作</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">3</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#4-实验"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">4 实验</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-1定量结果摘要"><span class="toc_mobile_items-number">5.1.</span> <span class="toc_mobile_items-text">4.1定量结果摘要</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-2合成数据"><span class="toc_mobile_items-number">5.2.</span> <span class="toc_mobile_items-text">4.2合成数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-3眼睛固定数据"><span class="toc_mobile_items-number">5.3.</span> <span class="toc_mobile_items-text">4.3眼睛固定数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-4流式细胞仪数据"><span class="toc_mobile_items-number">5.4.</span> <span class="toc_mobile_items-text">4.4流式细胞仪数据</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#5-结论"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">5 结论</span></a></li></ol></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/nightshift.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zindex="-1" data-click="false"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();</script></body></html>